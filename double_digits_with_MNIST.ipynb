{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "double_digits with MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDlWLbfkJtvu",
        "cellView": "form"
      },
      "source": [
        "#@title Everything not mine is copyright 2020 Google LLC and others.  Dbl-click for more information.\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "# Yann LeCun and Corinna Cortes hold the copyright of MNIST dataset,\n",
        "# which is a derivative work from original NIST datasets. \n",
        "# MNIST dataset is made available under the terms of the \n",
        "# Creative Commons Attribution-Share Alike 3.0 license."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SBux8qWSzPz"
      },
      "source": [
        "**This Notebook is heavily modified from the MLCC programming project with single-digit images here:**\n",
        "\n",
        "https://colab.research.google.com/github/google/eng-edu/blob/master/ml/cc/exercises/multi-class_classification_with_MNIST.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxj8yVh4mFl5"
      },
      "source": [
        "**[Taken from the original MLCC \"project\" with single digit images. I will start with these images and then merge them together, pixel-array by pixel-array, to create a new train/test set of 100 double-digit images.]**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n9_cTveKmse",
        "cellView": "both"
      },
      "source": [
        "# load some standard utilities.\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import random as rd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# The following lines adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.3f}\".format\n",
        "\n",
        "# The following line improves formatting when ouputting NumPy arrays.\n",
        "np.set_printoptions(linewidth = 200)\n",
        "\n",
        "print(\"Loaded modules.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZlvdpyYKx7V",
        "cellView": "both"
      },
      "source": [
        "# load the dataset.\n",
        "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(\"Loaded the train and test sets.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6jzIZm1vDZ",
        "cellView": "both"
      },
      "source": [
        "# THIS FUNCTION MERGES TWO RANDOMLY CHOSEN SINGLE-DIGIT IMAGES\n",
        "# INTO ONE DOUBLE-DIGIT IMAGE REPRESENTING NUMBERS 0 TO 99.\n",
        "# THE \"CORRECT ANSWER\" FOR THE DOUBLE-DIGIT IMAGE IS CALCULATED\n",
        "# FROM THE ANSWERS GIVEN FOR THE SINGLE-DIGIT IMAGES (IN Y_TRAIN\n",
        "# AND Y_TEST).\n",
        "\n",
        "def doubleDigits(images=x_train,answers=y_train):\n",
        "    im = np.array([28,56])\n",
        "    #im.resize((28,56))\n",
        "    tens = rd.randint(0,len(images)-1) # HERE IS WHERE THE \n",
        "    ones = rd.randint(0,len(images)-1) # RANDOM NUMS COME FROM\n",
        "    dubs = images[tens].copy()             # IMAGE ON THE LEFT\n",
        "    digs = images[ones].copy()             # IMAGE ON THE RIGHT\n",
        "    for i,col in enumerate(dubs.transpose()):\n",
        "        im[:,i] = col\n",
        "    for i,col in enumerate(digs.transpose()):\n",
        "        im[:,i+28] = col\n",
        "    answer = answers[tens]*10 + answers[ones] #CALCULATE THE RIGHT\n",
        "    return im, answer                         #ANSWER NUMERICALLY                \n",
        "    #returns image array, list of answers\n",
        "print(\"Loaded function doubleDigits.\")\n",
        "\n",
        "def plot_curve(epochs, hist, metric):\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Value\")\n",
        "\n",
        "  x = hist[metric]\n",
        "  plt.plot(epochs[1:], x[1:], label=metric)\n",
        "\n",
        "  plt.legend()\n",
        "\n",
        "print(\"Loaded the plot_curve function to be called after training.\")\n",
        "\n",
        "# THIS FUNCTION WILL BE CALLED TO GENERATE A NEW \n",
        "# TRAINING SET OF RANDOM DOUBLE-DIGIT IMAGES TO WORK WITH\n",
        "\n",
        "def getDoubleDigits(x_df=x_train,y_df=y_train,how_many=1):\n",
        "    '''\n",
        "        Get a trainable set of how_many double-digit images. \n",
        "        Returns two objects:\n",
        "            - xdf, an array with how_many 28x56 images (ie. of shape(how_many,28,56)),\n",
        "            - ydf, a 1D array with the corresponding labels (shape(how_many,1))\n",
        "    '''\n",
        "    yy = []\n",
        "    xx = []\n",
        "    for i in range(how_many):\n",
        "        dd, ans = doubleDigits(x_df,y_df)\n",
        "        yy += [ans]\n",
        "        xx.append(dd)\n",
        "    return xx, yy\n",
        "\n",
        "print(\"Loaded function getDoubleDigits.\")\n",
        "\n",
        "# AND FINALLY CALL FUNCTION gDD TO SHOW AN EXAMPLE OF A \n",
        "# CONSTRUCTED IMAGE AND ANSWER TO MAKE SURE IT LOOKS OK\n",
        "xdf, ydf = getDoubleDigits(x_test,y_test,3)\n",
        "print('Random example:')\n",
        "print('Answer:',ydf[2])\n",
        "plt.imshow(xdf[2])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTEooB0awn_C",
        "cellView": "both"
      },
      "source": [
        "nrows = 1\n",
        "ncols = 4\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4) \n",
        "x_df, y_df = getDoubleDigits(x_train,y_train,4) # CALL THE gDD FUNCTION TO CONSTRUCT A NEW\n",
        "print(\"Answers:\",y_df)                          # RANDOM SAMPLE OF 4 DOUBLE-DIGIT IMAGES\n",
        "\n",
        "for i, img in enumerate(x_df):\n",
        "    splot = plt.subplot(nrows, ncols, i + 1)\n",
        "    splot.axis('Off')\n",
        "    plt.imshow(img)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQljE-wizDw"
      },
      "source": [
        "# HERE IS WHERE WE CONSTRUCT N DOUBLE-DIGIT IMAGES TO TRAIN ON\n",
        "# PLUS ANOTHER N//10 IMAGES TO TEST ON AFTER TRAINING.\n",
        "\n",
        "xts, yts = getDoubleDigits(x_test,y_test,4000)\n",
        "x_test_normalized = np.array(xts) / 255.\n",
        "y_test_norm = np.array(yts)\n",
        "print(\"Made\",4000,\"new double-digit images to test on.\")\n",
        "xtn, ytn = getDoubleDigits(x_train,y_train,40000)\n",
        "x_train_normalized = np.array(xtn) / 255.\n",
        "y_train_norm = np.array(ytn)\n",
        "print(\"Made\",40000,\"new double-digit images to train on.\")\n",
        "print(\"DONE!\")\n",
        "# WHEN ITS DONE IT WILL PRINT \"DONE\"!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krymMuUyB1e-"
      },
      "source": [
        "train_40000 = np.array(xtn).reshape(len(ytn),28*56)\n",
        "valid_4000 = np.array(xts).reshape(len(yts),28*56)\n",
        "train_40000 = pd.Dataframe(train_40000)\n",
        "valid_4000 = pd.Dataframe(valid_4000)\n",
        "train_40000[\"target\"] = ytn\n",
        "valid_4000[\"target\"] = yts\n",
        "train_40000.to_csv(\"doubledigits_train_40000\")\n",
        "valid_4000.to_csv(\"doubledigits_valid_4000\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3014ezH3C7jT"
      },
      "source": [
        "## Create a deep neural net model\n",
        "\n",
        "[Text from the original project for single digits.]\n",
        "\n",
        "The `create_model` function defines the topography of the deep neural net, specifying the following:\n",
        "\n",
        "* The number of [layers](https://developers.google.com/machine-learning/glossary/#layer) in the deep neural net.\n",
        "* The number of [nodes](https://developers.google.com/machine-learning/glossary/#node) in each layer.\n",
        "* Any [regularization](https://developers.google.com/machine-learning/glossary/#regularization) layers.\n",
        "\n",
        "The `create_model` function also defines the [activation function](https://developers.google.com/machine-learning/glossary/#activation_function) of each layer.  The activation function of the output layer is [softmax](https://developers.google.com/machine-learning/glossary/#softmax), which will yield (100) different outputs for each example. Each of the (100) outputs provides the probability that the input example is a certain digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5AI0Drej0KS"
      },
      "source": [
        "\n",
        "def create_model(learning_rate):\n",
        "    \"\"\"Create and compile a deep neural net.\"\"\"  \n",
        "    # Define the kind of model to use.\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    # The double digit images are stored in two-dimensional arrays of 28x56 pixels \n",
        "    # each. The input layer flattens those two-dimensional arrays into \n",
        "    # one-dimensional 1568-element arrays.\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 56)))\n",
        "\n",
        "    # The first interconnected layer will have 200 \"neurons\" (each of which \n",
        "    # is connected to each element in the input array). \n",
        "    # A \"weight\" will be randomly assigned to each node-to-node connection;\n",
        "    # all those weights will get adjusted on each pass during training.\n",
        "    # That's how the \"learning\" happens!\n",
        "    model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
        "    # This line will help keep the model from \"overlearning\" the training set,\n",
        "    # which can happen, not good. \n",
        "    model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "\n",
        "    # Define the second interconnected layer, this one with 100 \"neurons\".   \n",
        "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
        "\n",
        "    # Define the output layer. This layer must have exactly 100 \"neurons\", \n",
        "    # one for each possible output value (representing the numbers 0 to 99).\n",
        "    # With Softmax activation, the model will assign each output node the\n",
        "    # probability that the model thinks it's the corresponding double-digit number.\n",
        "    # The one with the highest probability will then be chosen as the model's\n",
        "    # \"best guess\" for each example given.\n",
        "    model.add(tf.keras.layers.Dense(units=100, activation='softmax'))     \n",
        "                            \n",
        "    # Build the model with built-in metrics to measure the progress it's making\n",
        "    # with the training set.  \n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                    loss=\"sparse_categorical_crossentropy\",\n",
        "                    metrics=['accuracy']) \n",
        "    return model \n",
        "\n",
        "# THIS FUNCTION WILL TRAIN THE MODEL ON THE TRAINING SET #\n",
        "def train_model(model, train_features, train_label, epochs,\n",
        "                batch_size=None, validation_split=0.1):\n",
        "\n",
        "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True, \n",
        "                      validation_split=validation_split)\n",
        " \n",
        "    # Get a snapshot of the model's metrics after each round of training\n",
        "    # to measure its progress.\n",
        "    epochs = history.epoch\n",
        "    hist = pd.DataFrame(history.history)\n",
        "    return epochs, hist    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-IXYVfvM4gD"
      },
      "source": [
        "## Invoke the previous functions to train on the train set and evaluate on the test set.\n",
        "\n",
        "Run the following code cell to invoke the preceding functions and actually train the model on the training set. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj3v5EKQFY8s",
        "cellView": "both"
      },
      "source": [
        "# These variables are the adjustable \"hyperparameters\" of the model.\n",
        "learning_rate = 0.001\n",
        "epochs = 20\n",
        "batch_size = 500\n",
        "validation_split = 0.1\n",
        "# \"epochs\" is the number of times the model makes adjustments to all\n",
        "# the weights for all the inter-neuron connections... which is a lot! \n",
        "# This should just take a couple of minutes; you can monitor its progress\n",
        "# in the output window below.\n",
        "\n",
        "# CREATE A NEW NEURAL NETWORK ACCORDING TO SPECIFICATIONS.\n",
        "my_model = create_model(learning_rate)\n",
        "\n",
        "# TRAIN IT ON THE \"NORMALIZED\" TRAINING SET:\n",
        "epochs, hist = train_model(my_model, x_train_normalized, y_train_norm, \n",
        "                           epochs, batch_size, validation_split)\n",
        "\n",
        "# EVALUATE AGAINST THE TEST SET:\n",
        "print(\"\\n Evaluate the new model against the test set:\")\n",
        "my_model.evaluate(x=x_test_normalized, y=y_test_norm, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOwFlKU0yjfh"
      },
      "source": [
        "x_train_normalized.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6QCoQqRvRfb"
      },
      "source": [
        "# Plot a graph of the 'accuracy' metric vs. epochs:\n",
        "plot_curve(epochs, hist, 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKFOumI6vg4T"
      },
      "source": [
        "# THIS FUNCTION TRANSLATES THE OUTPUT FROM THE NEURAL NETWORK\n",
        "# INTO A \"BEST GUESS\" FOR EACH EXAMPLE BASED ON THE RELATIVE\n",
        "# PROBABILITY IT ESTIMATES FOR EACH NUMBER 0 TO 99.\n",
        "\n",
        "def getAnswers(how_many=10):  \n",
        "    answers = pd.DataFrame(columns=['Answer','Guess','P(A)','P(G)'])  \n",
        "    answers['Answer'] = y_test_norm[:how_many]\n",
        "    predicts = my_model.predict(x_test_normalized).round(5)\n",
        "    for j in range(0,how_many): # how_many is the number of examples to guess\n",
        "        probs = predicts[j] # one row of 100 probabilities \n",
        "        maxr = max(probs)   # top probability\n",
        "        for i in range(0,100):\n",
        "            if probs[i] == maxr:\n",
        "                answers.at[j,'Guess'] = i\n",
        "                answers.at[j,'P(G)'] = maxr*100\n",
        "            if i == answers['Answer'][j]:\n",
        "                answers.at[j,'P(A)'] = probs[i]*100\n",
        "    return answers\n",
        "print(\"Loaded function getAnswers.\")\n",
        "print(\"Getting answers...\" )\n",
        "\n",
        "# LOAD UP ALL THE GUESSES (W/ PROBABILITES) FOR \n",
        "# EACH EXAMPLE IMAGE IN THE NORMALIZED TEST SET\n",
        "answers = getAnswers(len(x_test_normalized))\n",
        "answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkl_yxX8GlEt"
      },
      "source": [
        "# FIND THE *WRONG* GUESSES!\n",
        "wrongs = pd.DataFrame(index=answers.index,columns=['Mask'])\n",
        "for row in answers.index:\n",
        "    if answers['Answer'][row] == answers['Guess'][row]:\n",
        "        wrongs['Mask'][row] = False\n",
        "    else:\n",
        "        wrongs['Mask'][row] = True\n",
        "\n",
        "# LOCATE AND PRINT OUT THE LIST OF WRONGS       \n",
        "a = answers.loc[wrongs['Mask']]\n",
        "w = len(a) \n",
        "t = len(x_test_normalized)\n",
        "print(w,\"wrong out of\",t,\"guesses.\")\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ4riZ5VmQbV"
      },
      "source": [
        "# FIND OUT WHICH NUMBERS IT HAD THE MOST TROUBLE WITH\n",
        "ww = []\n",
        "for i in range(0,100):\n",
        "    w = len((answers.loc[lambda a: a['Answer'] == i]).loc[wrongs['Mask']])\n",
        "    ww += [w]\n",
        "attempts = pd.DataFrame(ww)\n",
        "attempts.sort_values(0).tail(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bffPxjYDlEYJ"
      },
      "source": [
        "# LAST BUT NOT LEAST...\n",
        "# THIS CELL SHOWS WHAT SOME OF THE *WRONG* GUESSES WERE.\n",
        "#\n",
        "# IT SHOWS THE IMAGE THE ALGORITHM HAD TO WORK WITH\n",
        "# ALONG WITH ITS \"BEST GUESS\" AND THE LABELED ANSWER\n",
        "\n",
        "# RUN THE CELL A FEW TIMES TO SEE A FEW EXAMPLES OF WHERE IT FAILED!\n",
        "\n",
        "g = answers['Guess'].loc[wrongs['Mask']]\n",
        "a = answers['Answer'].loc[wrongs['Mask']]\n",
        "x = rd.choice(g.index)  #RANDOMLY SELECT ONE OF THE WRONG GUESSES\n",
        "pa = round(answers['P(A)'][x],2)\n",
        "pg = round(answers['P(G)'][x],2)\n",
        "print(\"Answer[\",x,\"] is\",a[x],\"with estimated probability\",pa,\"\\n\")\n",
        "print(\"Guess[\",x,\"] was\",g[x],\"with estimated probability\",pg,\"\\n\")\n",
        "plt.imshow(x_test_normalized[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xo6ne4dOPIl"
      },
      "source": [
        "And that's that, for now!\n",
        "\n",
        "Next step: teach an algorithm to add and subtract just by giving it handwritten digits and handwritten \"+\",\"-\",\"=\" signs!!"
      ]
    }
  ]
}