{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "arithmetic_double_digits.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qfja9tMaB1ZH"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidabelin/doubledigits/blob/main/arithmetic_double_digits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfja9tMaB1ZH"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkNQqjZaB4_u"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHK6DyunSbs4"
      },
      "source": [
        "# Handwritten Digit Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLy3pthUS0D2",
        "cellView": "form"
      },
      "source": [
        "#@title IMPORTS\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sbn\n",
        "\n",
        "import zipfile\n",
        "import math\n",
        "import random as rd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, signal\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "#from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, InputLayer, Input\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb99wQJzCCk6"
      },
      "source": [
        "### **--------- TO DO ------------**\n",
        "\n",
        "*   Put in some noise.\n",
        "*   Collect and display output from just the NN layers?\n",
        "*   Prepare for github\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UY6KJV6z6l7_"
      },
      "source": [
        "## Construct the Input Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8Y3AFF5pgJZ"
      },
      "source": [
        "#Load\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(imgs_train, ans_train), (imgs_test, ans_test) = mnist.load_data()\n",
        "\n",
        "# Knobs\n",
        "nrows = 2\n",
        "ncols = 5\n",
        "\n",
        "N = 10000 # num training examples\n",
        "image_size = (28,56)\n",
        "\n",
        "# Data\n",
        "imgs_train.shape, imgs_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf0G6g1aAKhM"
      },
      "source": [
        "im = np.zeros(image_size)\n",
        "left_index = rd.randint(0,len(ans_train)-1)   \n",
        "right_index = rd.randint(0,len(ans_train)-1) \n",
        "for i in range(image_size[1]//2):\n",
        "    im[:,i] = imgs_train[left_index,:,i]\n",
        "    im[:,i+image_size[1]//2] = imgs_train[right_index,:,i]\n",
        "\n",
        "maxswer = np.max([ans_train[left_index],ans_train[right_index]])\n",
        "minswer = np.min([ans_train[left_index],ans_train[right_index]])\n",
        "answer = maxswer*10 + minswer\n",
        "\n",
        "print (\"Answer:\", maxswer,\"* 10 +\",minswer,\"=\",answer)\n",
        "#print (\"Answer:\", ans_train[left_index],\"<>\",ans_train[right_index],\"=\",answer)\n",
        "plt.imshow(im)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VIPJoTbs6QM"
      },
      "source": [
        "def getOperator(image, operation):\n",
        "    if operation == 'Multiply':     #MULTIPLY\n",
        "        for row in range(11,18):\n",
        "            image[28-row,row+14] = 255\n",
        "            image[row,row+14] = 255\n",
        "            image[row,row+15] /= 2\n",
        "            image[row,row+15] += 255/row\n",
        "            image[row,row+13] /= 2\n",
        "            image[row,row+13] += 50 + 512/row\n",
        "            image[28-row,row+13] /= 2\n",
        "            image[28-row,row+13] += 100 + 255/(28-row)\n",
        "            image[28-row,row+15] /= 2\n",
        "            image[28-row,row+15] += 512/(28-row)\n",
        "    else:\n",
        "        if operation == 'Divide':       #DIVIDE\n",
        "            for row in range(8,21):\n",
        "                image[28-row,row+14] = 255\n",
        "                image[28-row,row+13] /= 2\n",
        "                image[28-row,row+13] += 60 + 255/row\n",
        "                image[28-row,row+15] /= 2\n",
        "                image[28-row,row+15] += 512/(28-row)\n",
        "        else:\n",
        "            image[14,24:32] = 255  # MINUS SIGN (FOR BOTH ADD AND SUB)\n",
        "            if (image[13,24:32] > 255-99).any():  \n",
        "                image[13,24:32] /= 2\n",
        "            image[13,24:32] += 99\n",
        "            if (image[15,25:31] > 255-33).any():\n",
        "                image[15,25:31] /= 2\n",
        "            image[15,25:31] += 33\n",
        "        \n",
        "            if operation == 'Add': \n",
        "                image[10:18,28] = 255\n",
        "                if (image[10:18,27] > 255-99).any():\n",
        "                    image[10:18,27] /= 2\n",
        "                image[10:18,27] += 99  # PLUS SIGN\n",
        "\n",
        "    return image\n",
        "\n",
        "op = rd.choice(['Add','Multiply','Subtract','Divide'])\n",
        "image = getOperator(np.zeros((28,56)),op)\n",
        "#(image[9:19,23:33] > 255).any()\n",
        "print (op)\n",
        "print(image[9:19,23:33])\n",
        "plt.imshow(image)#[9:19,23:33])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6jzIZm1vDZ",
        "cellView": "both"
      },
      "source": [
        "def doubleDigits(images=imgs_train,answers=ans_train,ops=True):\n",
        "\n",
        "    image = np.zeros(image_size)\n",
        "    left_index = rd.randint(0, len(answers)-1)   \n",
        "    right_index = rd.randint(0, len(answers)-1)\n",
        "    for i in range(28):                 # PUT IN THE DIGITS\n",
        "        image[:,i] = images[left_index,:,i]\n",
        "        image[:,i+28] = images[right_index,:,i]\n",
        "    if ops:                           # MAKE ARITHMETIC SET\n",
        "        operation =  rd.choice(['Add','Multiply','Subtract','Divide']) # TRUE+*  FALSE-/\n",
        "        if operation == 'Add':                       #ADD\n",
        "                answer = answers[left_index] + answers[right_index] \n",
        "        else: \n",
        "            if operation == 'Multiply':                   #MULTIPLY\n",
        "                    answer = answers[left_index] * answers[right_index]\n",
        "            else:               #SUBTRACT AND DIVIDE\n",
        "                maxswer = np.max([answers[left_index],answers[right_index]])\n",
        "                minswer = np.min([answers[left_index],answers[right_index]])\n",
        "                if operation == 'Subtract':       #SUBTRACT\n",
        "                    answer = maxswer - minswer\n",
        "                else:                               #DIVIDE        \n",
        "                    if minswer == 0:\n",
        "                        answer = 99\n",
        "                    else:\n",
        "                        answer = int(round(maxswer / minswer))\n",
        "        image = getOperator(image, operation)\n",
        "\n",
        "    else:                # DOUBLE DIGITS BY DEFAULT\n",
        "        answer = answers[left_index]*10 + answers[right_index]   \n",
        "\n",
        "    return image, answer              \n",
        "    #returns image array, list of answers\n",
        "print(\"Loaded function doubleDigits.\")\n",
        "\n",
        "def getDoubleDigits(images=imgs_train,answers=ans_train,how_many=1,ops=True):\n",
        "    yy = []\n",
        "    xx = []\n",
        "    for i in range(how_many):\n",
        "        dd, ans = doubleDigits(images,answers,ops)\n",
        "        yy += [ans]\n",
        "        xx.append(dd)\n",
        "        if i%500 == 0:\n",
        "            print(\"Loaded:\",i,\"of,\",how_many,\"examples...\")\n",
        "            clear_output(wait=True)\n",
        "    print(\"Loaded:\",how_many,\"examples.\")\n",
        "    return xx, yy\n",
        "\n",
        "print(\"Loaded function getDoubleDigits.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oekONaV-CcrI"
      },
      "source": [
        "# AND FINALLY CALL FUNCTION gDD TO SHOW AN EXAMPLE OF A \n",
        "# CONSTRUCTED IMAGE AND ANSWER TO MAKE SURE IT LOOKS OK\n",
        "x, y = getDoubleDigits(imgs_test,ans_test,ops=True)\n",
        "print('~Random example~')\n",
        "print('Answer:',y[0])\n",
        "plt.imshow(x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YQljE-wizDw"
      },
      "source": [
        "######### GENERATE DD TRAINING DATA FOR FIRST MODEL #################\n",
        "xts, y_test = getDoubleDigits(imgs_test,ans_test,N//10,ops=True)\n",
        "x_test = np.array(xts) / 255.\n",
        "print(\"Made\",N//10,\"new double-digit images to test on.\")\n",
        "\n",
        "xtn, y_train = getDoubleDigits(imgs_train,ans_train,N,ops=True)\n",
        "x_train = np.array(xtn) / 255.\n",
        "print(\"Made\",N,\"new double-digit images to train on.\")\n",
        "\n",
        "######################## Add a channels dimension\n",
        "x_train = x_train[..., tf.newaxis].astype(\"float32\")\n",
        "x_test = x_test[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "####################### TF Datasets for input\n",
        "train_ds = tf.data.Dataset.from_tensor_slices( (x_train, y_train) )\n",
        "test_ds = tf.data.Dataset.from_tensor_slices( (x_test, y_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "# Build Convolutional NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqkMcZKCpOAa"
      },
      "source": [
        "###################### Build CNN as first model\n",
        "input_layer = layers.Input(shape=(image_size[0], image_size[1], 1))\n",
        "\n",
        "x = layers.Conv2D(10, 2, padding='same', activation='relu')(input_layer)\n",
        "#x = layers.Conv2D(100, 2, padding='same', activation='relu')(x) \n",
        "x = layers.MaxPooling2D(2)(x)\n",
        "x = layers.Conv2D(10, 2, padding='same', activation='relu')(x) \n",
        "#x = layers.MaxPooling2D((4,8))(x)\n",
        "x = layers.Flatten()(x)\n",
        "output_layer = layers.Dense(100, activation='softmax')(x)\n",
        "######################### 100 or else dict(list(set(y_train))!\n",
        "\n",
        "####################### Build\n",
        "model = Model(input_layer, output_layer)\n",
        "\n",
        "####################### Compile\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=Adam(lr=0.0025), #0.0075\n",
        "              metrics=['acc'])\n",
        "    \n",
        "####################### Layer-outputs model\n",
        "layer_outputs = [layer.output for layer in model.layers[1:]]\n",
        "output_model = Model(input_layer, layer_outputs)\n",
        "\n",
        "####################### History containers\n",
        "answers, guesses = [],[]\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training / Loading and reloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb1_lgobv81m"
      },
      "source": [
        "############################# Train the CNN first:\n",
        "mhistory = model.fit(train_ds.shuffle(N+1).batch(N//10),\n",
        "                     validation_data=test_ds.batch(N//200),  \n",
        "                     epochs=1,  \n",
        "                     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkK2bOVgroVO"
      },
      "source": [
        "##################### Put in a small NN at the end\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "    if \"conv2d\" in layer.name: out_layer = layer.name\n",
        "\n",
        "x = model.get_layer(out_layer).output\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(100, activation='relu')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "new_output_layer = layers.Dense(100, activation='softmax')(x)\n",
        "new_model = Model(input_layer, new_output_layer)\n",
        "new_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer=Adam(lr=0.0025), #0.0075\n",
        "              metrics=['acc'])\n",
        "\n",
        "####################### Layer-outputs for new model\n",
        "new_layer_outputs = [layer.output for layer in new_model.layers[1:]]\n",
        "new_output_model = Model(input_layer, new_layer_outputs)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54scRXv4MOwl"
      },
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23FFl9aLsnSF"
      },
      "source": [
        "############################# Train new_model\n",
        "new_history = new_model.fit(train_ds.shuffle(N+1).batch(N//100),\n",
        "                            validation_data=test_ds.batch(N//200),  \n",
        "                            epochs=20,  \n",
        "                            verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jVH5faO7YyI"
      },
      "source": [
        "#plotLearningCurves(new_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8EHQyWGDvWz"
      },
      "source": [
        "### Visualizing Intermediate Representations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oj0gTIy4k60",
        "cellView": "form"
      },
      "source": [
        "#@title Display learning curves \n",
        "def plotLearningCurves(history=mhistory):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    plt.plot(epochs, acc)\n",
        "    plt.plot(epochs, val_acc)\n",
        "    plt.title('Training and validation accuracy')\n",
        "\n",
        "    #plt.figure()\n",
        "\n",
        "    #plt.plot(epochs, loss)\n",
        "    #plt.plot(epochs, val_loss)\n",
        "    #plt.title('Training and validation loss')\n",
        "\n",
        "plotLearningCurves()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP5AH28uewTP",
        "cellView": "form"
      },
      "source": [
        "#@title Deprecated Functions NO_GUESSING() and NO_GET_RESULTS()\n",
        "def no_guessing(N=1,model=model,X=False):\n",
        "    answers, guesses = [],[]\n",
        "    for count in range(N):\n",
        "        if X:\n",
        "            take1_ds = testX_ds.shuffle(10001).take(1)    \n",
        "        else:\n",
        "            take1_ds = test_ds.shuffle(10001).take(1)\n",
        "        for img, ans in take1_ds:\n",
        "            ans = ans.numpy()\n",
        "            img = img.numpy()                  # 28x56x1\n",
        "        img = img.reshape((1,) + img.shape)    # 1x28x56x1\n",
        "        guess_set = model.predict(img)\n",
        "        #guess = tf.random.categorical( guess_set, num_samples=1 ).numpy().squeeze()\n",
        "        guess = np.argmax(guess_set)\n",
        "        \n",
        "        answers += [ans]\n",
        "        guesses += [guess]\n",
        "        #pG += [guess_set[guess]]\n",
        "        #pA += [guess_set[answer]]\n",
        "        #print(\"Answer\",answer,\"\\tGuess\",guess)#, \"\\tp(A)\",pA,\"\\tp(G)\",pG)\n",
        "       \n",
        "        if count%20 == 0:\n",
        "            print ('Processing...',count,\"...\")\n",
        "            clear_output(wait=True)\n",
        "\n",
        "    return answers, guesses#, pA, pG\n",
        "\n",
        "def no_get_results(N=1,m=model,X=False):\n",
        "    no_results = pd.DataFrame(columns=['Answer','Guess'])#,'P(A)','P(G)'])\n",
        "    no_results['Answer'], no_results['Guess'] = no_guessing(N, m, X) #, results['P(A)'], results['P(G)'] \n",
        "    return no_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GzRKiG9XcaCf"
      },
      "source": [
        "#@title Functions GUESSING() and GET_RESULTS()\n",
        "def guessing(n=1,model=model,return_image=False):\n",
        "    answers, guesses, pA, pG = [],[],[],[]\n",
        "    for count in range(n):\n",
        "        take1_ds = test_ds.shuffle(N+1).take(1)\n",
        "        for img, ans in take1_ds:\n",
        "            ans = ans.numpy()\n",
        "            img = img.numpy()                  # eg. 28x56x1\n",
        "        img = img.reshape((1,) + img.shape)    # eg. 1x50x50x1\n",
        "        guess_set = model.predict(img).flatten()\n",
        "        #guess = tf.random.categorical( guess_set, num_samples=1 ).numpy().squeeze()\n",
        "        guess = np.argmax(guess_set)\n",
        "        \n",
        "        answers += [ans]\n",
        "        guesses += [guess]\n",
        "        pG += [guess_set[guess]]\n",
        "        pA += [guess_set[ans]]\n",
        "\n",
        "        print(\"Answer\",ans,\"\\tGuess\",guess, \"\\tp(A)\",round(pA[count],2),\"\\tp(G)\",round(pG[count],2))\n",
        "        if count%10 == 0:\n",
        "            print ('Processing...',count,\"...\")\n",
        "            clear_output(wait=True)\n",
        "\n",
        "    if return_image:\n",
        "        return answers, guesses, pA, pG, img\n",
        "    else:\n",
        "        return answers, guesses, pA, pG\n",
        "\n",
        "def get_results(n=1,m=model):\n",
        "    results = pd.DataFrame(columns=['Answer','Guess','P(A)','P(G)'])\n",
        "    results['Answer'], results['Guess'], results['P(A)'], results['P(G)'] = guessing(n, m) \n",
        "    return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgVhpl2X29A7"
      },
      "source": [
        "answers, guesses, pA, pG, img = guessing(1, return_image=True)\n",
        "print (answers[0], guesses[0])\n",
        "print (pA[0], pG[0])\n",
        "plt.imshow(img[0,:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqgpg-yl2tOh",
        "cellView": "form"
      },
      "source": [
        "#@title Show layer output from first model...\n",
        "\n",
        "# Take random image from the training set.\n",
        "take1_ds = test_ds.shuffle(10001).take(1)\n",
        "for img, ans in take1_ds:\n",
        "    img = img.numpy()\n",
        "    ans = ans.numpy()\n",
        "img = img.reshape((1,) + img.shape)    # np shape (1, 28, 28, 1)\n",
        "gue = model.predict(img)\n",
        "print(\"Answer:\",ans, \"\\tGuess:\",np.argmax(gue))\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(img[0,:,:,0])                 # np shape (28, 28)\n",
        "\n",
        "layer_output_maps = output_model.predict( img )\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "for layer_name, layer_map in zip(layer_names, layer_output_maps):\n",
        "    if len(layer_map.shape) == 4:# and not 'max_pooling' in layer_name:\n",
        "        n_maps = layer_map.shape[-1]  # number of maps\n",
        "        if n_maps > 10:\n",
        "            n_maps = 10\n",
        "        # Map has shape (1, rows, columns, n_features)\n",
        "        rows = layer_map.shape[1]\n",
        "        cols = layer_map.shape[2]\n",
        "        image_grid = np.zeros((rows, cols * n_maps))\n",
        "        \n",
        "        for i in range(n_maps):\n",
        "            x = layer_map[0, :, :, i]\n",
        "            x *= 255.0\n",
        "            image_grid[:, i * cols : (i + 1) * cols] = x\n",
        "            image_grid[:,i*cols] = 255.\n",
        "            image_grid[:,i*cols+1] = 0.\n",
        "            \n",
        "        scale = 2.           \n",
        "        plt.figure(figsize=(scale * n_maps, scale))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(image_grid, cmap='viridis')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_X5txK4fBxPE"
      },
      "source": [
        "#@title Show layer output from \"new model\" with small NN\n",
        "\n",
        "# Take random image from the training set.\n",
        "take1_ds = test_ds.shuffle(10001).take(1)\n",
        "for img, ans in take1_ds:\n",
        "    img = img.numpy()\n",
        "    ans = ans.numpy()\n",
        "img = img.reshape((1,) + img.shape)    # np shape (1, 28, 28, 1)\n",
        "gue = new_model.predict(img)\n",
        "print(\"Answer:\",ans, \"\\tGuess:\",np.argmax(gue))\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(img[0,:,:,0], cmap=\"binary_r\")                 # np shape (28, 28)\n",
        "\n",
        "layer_output_maps = new_output_model.predict( img )\n",
        "layer_names = [layer.name for layer in new_model.layers[1:]]\n",
        "for layer_name, layer_map in zip(layer_names, layer_output_maps):\n",
        "    if len(layer_map.shape) == 4:# and not 'max_pooling' in layer_name:\n",
        "        n_maps = layer_map.shape[-1]  # number of maps\n",
        "        if n_maps > 10:\n",
        "            n_maps = 10\n",
        "        # Map has shape (1, rows, columns, n_features)\n",
        "        rows = layer_map.shape[1]\n",
        "        cols = layer_map.shape[2]\n",
        "        image_grid = np.zeros((rows, cols * n_maps))\n",
        "        \n",
        "        for i in range(n_maps):\n",
        "            x = layer_map[0, :, :, i]\n",
        "            x *= 255.0\n",
        "            image_grid[:, i * cols : (i + 1) * cols] = x\n",
        "            image_grid[:,i*cols] = 255.\n",
        "            image_grid[:,i*cols+1] = 0.\n",
        "            \n",
        "        scale = 2.           \n",
        "        plt.figure(figsize=(scale * n_maps, scale))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(image_grid, cmap='gray')\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql_FDtDXoNib"
      },
      "source": [
        "### examine results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dQJos2jAtCQ"
      },
      "source": [
        "results = get_results(100,new_model)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q67V1mIbgKrT"
      },
      "source": [
        "tv = results['Guess'] == results['Answer']\n",
        "wrongs = results.loc[~tv]\n",
        "wrongs.sort_values('Answer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plSaSqE970wE"
      },
      "source": [
        "#Build modelX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XC6jkplw70BT"
      },
      "source": [
        "######### GENERATE NEW TRAINING DATA  #################\n",
        "######### usually no need to get more data! ###########\n",
        "def get_new_data(n=N,ops=True):\n",
        "    xts, y_testX = getDoubleDigits(images=imgs_test,\n",
        "                                   answers=ans_test,\n",
        "                                   how_many=n,\n",
        "                                   ops=True)\n",
        "    x_testX = np.array(xts) / 255.\n",
        "    print(\"Made\",n,\"new images to test on.\")\n",
        "\n",
        "    xtn, y_trainX = getDoubleDigits(imgs_train,\n",
        "                                    ans_train,\n",
        "                                    n,\n",
        "                                    ops=True)\n",
        "    x_trainX = np.array(xtn) / 255.\n",
        "    print(\"Made\",n,\"new images to train on.\")\n",
        "\n",
        "    print(len(set(y_trainX)),\"unique labels:\",set(y_trainX))\n",
        "\n",
        "    ######################## Add a channels dimension\n",
        "    x_trainX = x_trainX[..., tf.newaxis].astype(\"float32\")\n",
        "    x_testX = x_testX[..., tf.newaxis].astype(\"float32\")\n",
        "\n",
        "    ####################### TF Datasets for input\n",
        "    trainX_ds = tf.data.Dataset.from_tensor_slices( (x_trainX, y_trainX) )\n",
        "    testX_ds = tf.data.Dataset.from_tensor_slices( (x_testX, y_testX) )\n",
        "\n",
        "    return x_trainX, y_trainX, x_testX, y_testX, trainX_ds, testX_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpBYDUB2e5C1"
      },
      "source": [
        "#x_trainX, y_trainX, x_testX, y_testX, trainX_ds, testX_ds = get_new_data(n=N,X=True)\n",
        "#x_trainX, y_trainX, x_testX, y_testX, trainX_ds, testX_ds = x_train, y_train, x_test, y_test, train_ds, test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXYI9P7au7dY"
      },
      "source": [
        "plt.imshow(rd.choice(x_train)[:,:,0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjbng1RWBt-s"
      },
      "source": [
        "###### ALTERNATIVE BUILD: NN MODEL ########### \n",
        "\n",
        "###### and optional CNN on top?\n",
        "#x = layers.Conv2D(5, 2, padding='same', activation='relu')(input_layer)\n",
        "#x = layers.Conv2D(10, 3, padding='same', activation='relu')(x) \n",
        "\n",
        "#x = layers.Dense(10, activation='relu')(input_layer)\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "\n",
        "\n",
        "########################### This works ###########################\n",
        "x = layers.Flatten()(input_layer)\n",
        "x = layers.Dense(100, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(100, activation='relu')(x) \n",
        "x = layers.Dropout(0.1)(x)\n",
        "output_layer = layers.Dense(100, activation='softmax')(x) \n",
        "modelX = Model(input_layer, output_layer)\n",
        "########################### ^^^^^^^^^^ ###########################\n",
        "\n",
        "\n",
        "####################### Compile\n",
        "modelX.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=Adam(lr=0.0025), #0.0025),\n",
        "              metrics=['acc'])\n",
        "    \n",
        "####################### Layer-outputs model\n",
        "layer_outputsX = [layer.output for layer in modelX.layers[1:]]\n",
        "output_modelX = Model(input_layer, layer_outputsX)\n",
        "\n",
        "####################### History containers\n",
        "answersX, guessesX = [],[]\n",
        "\n",
        "####################### Summary\n",
        "modelX.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw-8-L8z3QOA"
      },
      "source": [
        "############################# Train modelX\n",
        "historyX = modelX.fit(train_ds.shuffle(N+1).batch(N//100), \n",
        "                     epochs=20,  \n",
        "                     validation_data=test_ds.batch(10), \n",
        "                     verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3zNOJnKkfEI"
      },
      "source": [
        "plotLearningCurves(historyX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "MVUEFNqu_88P"
      },
      "source": [
        "#@title Show layer output from MODELX ...\n",
        "\n",
        "# Take random image from the training set.\n",
        "take1_ds = test_ds.shuffle(10001).take(1)\n",
        "for img, ans in take1_ds:\n",
        "    img = img.numpy()\n",
        "    ans = ans.numpy()\n",
        "img = img.reshape((1,) + img.shape)    # np shape (1, 28, 28, 1)\n",
        "gue = modelX.predict(img)\n",
        "print(\"Answer:\",ans, \"\\tGuess:\",np.argmax(gue))\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(img[0,:,:,0])                 # np shape (28, 28)\n",
        "\n",
        "layer_output_maps = output_modelX.predict( img )\n",
        "layer_names = [layer.name for layer in modelX.layers[1:]]\n",
        "for layer_name, layer_map in zip(layer_names, layer_output_maps):\n",
        "    if \"flatten\" in layer_name: \n",
        "        layer_map = layer_map.reshape(1,image_size[0],image_size[1])\n",
        "        n_maps = layer_map.shape[0]  # 1 = number of maps\n",
        "\n",
        "        # Map has shape (1, rows, columns)\n",
        "        #rows = layer_map.shape[1]\n",
        "        #cols = layer_map.shape[2]\n",
        "        #image_grid = np.zeros((rows, cols))\n",
        "        \n",
        "        #for i in range(n_maps):\n",
        "        x = layer_map[0, :, :]\n",
        "        #x *= 255.0\n",
        "        #image_grid[:, cols : 2 * cols] = x\n",
        "            \n",
        "        scale = 2.           \n",
        "        plt.figure(figsize=(scale * n_maps, scale))\n",
        "        plt.title(layer_name)\n",
        "        plt.grid(False)\n",
        "        plt.imshow(x)  #(image_grid, cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vGOhYiQDrcP"
      },
      "source": [
        "layer_output_maps = output_modelX.predict( img )\n",
        "layer_names = [layer.name for layer in modelX.layers[1:]]\n",
        "for layer_name, layer_map in zip(layer_names, layer_output_maps):\n",
        "    if \"flatten\" in layer_name:#len(layer_map.shape) == 4:# and not 'max_pooling' in layer_name:\n",
        "         layer_map = layer_map.reshape(1,28,56)\n",
        "    print (layer_name, layer_map.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDEsLTrtEoOp"
      },
      "source": [
        "####################### Layer-outputs model\n",
        "#layer_outputsX = [layer.output for layer in modelX.layers[1:]]\n",
        "#output_modelX = Model(input_layer, layer_outputsX)\n",
        "modelX_neurons = output_modelX.variables[0].numpy().T\n",
        "modelX_neurons_df = pd.DataFrame(modelX_neurons)\n",
        "neuronX_df = pd.DataFrame(modelX_neurons[2].reshape((28,56)))\n",
        "#neuronX_df              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rp4wzxeRAPx"
      },
      "source": [
        "plt.imshow(neuronX_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUx5J2uuhdbY"
      },
      "source": [
        "    #  x -= x.mean()\n",
        "    #  x /= x.std()\n",
        "    #  x *= 64\n",
        "    #  x += 128\n",
        "    #  x = np.clip(x, 0, 255).astype('uint8')\n",
        "    #  x /= 255\n",
        "    \n",
        "nxmin = min(neuronX_df.min())\n",
        "nxmax = max(neuronX_df.max())\n",
        "nxmean = np.mean(neuronX_df.mean())\n",
        "nxstd = np.mean(neuronX_df.std())\n",
        "print (nxmin,nxmax,nxmean,nxstd)\n",
        "print (\"nxmin*255, nxmax*255\", nxmin*255, nxmax*255)\n",
        "\n",
        "#neuronX_df *= 255.\n",
        "neuronX_df += nxstd\n",
        "neuronX_df.clip(0,nxmax)\n",
        "#neuronX_df *= 255\n",
        "\n",
        "plt.imshow(neuronX_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKfdiWGfAv6X"
      },
      "source": [
        "modelX.variables[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVHfQfZIBLaR"
      },
      "source": [
        "variablesX = modelX.variables[0].numpy()\n",
        "(vmin,vmax,vmean,vstd) = (variablesX.min(), variablesX.max(), variablesX.mean(), variablesX.std())\n",
        "(vmin,vmax,vmean,vstd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIimsIXaXh1V"
      },
      "source": [
        "variablesX = np.clip((variablesX + abs(vstd))*255,0,255)\n",
        "variablesX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbsywoxaP3-y"
      },
      "source": [
        "variables = modelX.variables[0].numpy()\n",
        "num_nodes = variables.shape[1]\n",
        "num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "fig, axes = plt.subplots(num_rows, 10, figsize=(40, 2 * num_rows))\n",
        "for coef, ax in zip(variables.T, axes.ravel()):\n",
        "    # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "    coef = coef\n",
        "    ax.matshow(coef.reshape(image_size), cmap=plt.cm.viridis)\n",
        "    ax.set_xticks(())\n",
        "    ax.set_yticks(())\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tfeF6q2r2N"
      },
      "source": [
        "resultsX = get_results(100, modelX)\n",
        "resultsX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ98wKTVy3xR"
      },
      "source": [
        "plt.scatter(results['Guess'],results['Answer'])\n",
        "plt.scatter(resultsX['Guess'],resultsX['Answer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfPbuESofFCB"
      },
      "source": [
        "tvX = resultsX['Guess'] == resultsX['Answer']\n",
        "wrongsX = resultsX.loc[~tvX]\n",
        "#wrongsX.shape#, \n",
        "wrongsX.sort_values('Answer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pTxgNlzfW2H"
      },
      "source": [
        "# \"one shot iterator\"\n",
        "\n",
        "answers, guesses, pA, pG, img = guessing(1, model=modelX, return_image=True)\n",
        "print (\"Label:\", answers[0], \"\\tPredict:\", guesses[0])\n",
        "print (\"pLabel =\",pA[0], \"\\tpPredict = \", pG[0])\n",
        "plt.imshow(img[0,:,:,0],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSHokwPXVLdU"
      },
      "source": [
        "def showWeights():\n",
        "    weights0 = modelX.weights[0].numpy()\n",
        "    num_nodes = weights0.shape[1]\n",
        "    num_rows = int(math.ceil(num_nodes / 10.0))\n",
        "    fig, axes = plt.subplots(num_rows, 10, figsize=(40, 2 * num_rows))\n",
        "    for coef, ax in zip(weights0.T, axes.ravel()):\n",
        "        # Weights in coef is reshaped from 1x784 to 28x28.\n",
        "        ax.matshow(coef.reshape(image_size), cmap=plt.cm.bone)\n",
        "        ax.set_xticks(())\n",
        "        ax.set_yticks(())\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYGDEzmOqT9B"
      },
      "source": [
        "showWeights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhwxJusKu8Gg"
      },
      "source": [
        "#dense0 = pd.DataFrame(modelX.variables[0].numpy().T)\n",
        "#d0_neurons = np.zeros((100,28,56))\n",
        "#for i in range(dense0.shape[0]):\n",
        "#    d0_neurons[i] = np.reshape(list(dense0.iloc[i]),image_size)\n",
        "#plt.imshow(d0_neurons[7])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}